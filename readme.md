# Prompt Preprocessor: Sistema Inteligente de Validaci√≥n de Prompts

## üéØ Objetivo
Dise√±ar un sistema de preprocesamiento de prompts que:
- Valide y corrija entradas antes de enviarlas a modelos de IA
- Optimice la calidad y seguridad de las generaciones
- Mitigue riesgos potenciales en la interacci√≥n con IA

## üõ°Ô∏è Caracter√≠sticas Principales
- Correcci√≥n gramatical autom√°tica
- Detecci√≥n de lenguaje da√±ino o inapropiado
- Evaluaci√≥n de sesgos y contenido sensible
- Mejora de la claridad y precisi√≥n de prompts

## üèóÔ∏è Arquitectura
- **Backend:** Azure Functions
- **Servicios de Seguridad:** 
  * Azure Content Safety
  * OpenAI (Modelo GPT para mejora de prompts)
- **Procesamiento de Lenguaje:** 
  * spaCy
  * TextBlob

## üîí Componentes de Seguridad
- An√°lisis de riesgos de contenido
- Filtrado de lenguaje inapropiado
- Sugerencias de alternativas √©ticas y constructivas
---

## ‚öôÔ∏è **Configuraci√≥n Paso a Paso**  

### 1Ô∏è‚É£ **Crear escenario en Python/local**
```
# Crear proyecto de Functions
func init myFunctionApp --worker-runtime python

# Entrar al directorio
cd myFunctionApp
```
- Debe quedar esta estructura: 
```
myFunctionApp/
‚îú‚îÄ‚îÄ function_app.py
‚îú‚îÄ‚îÄ host.json
‚îú‚îÄ‚îÄ local.settings.json
‚îî‚îÄ‚îÄ requirements.txt
```
### 2Ô∏è‚É£ **Actualizamos el Homebrew (solo para Linux/Mac) e instalamos CLI y CORE TOOLS de Azure**
```
# Instalar Azure CLI
brew update
brew install azure-cli
```
```
# Instalar Azure Functions Core Tools
brew tap azure/functions
# Linux/Mac:
brew install azure-functions-core-tools@4 
# Windows:
npm install -g azure-functions-core-tools@4 #Windows
choco install azure-functions-core-tools-4  # considerar tambi√©n si usa Chocolatey
```
```
# Verificar instalaciones
az --version
func --version
```
### 3Ô∏è‚É£ **Completamos los archivos:**

1. Codigo en `function_app.py`:
```
import azure.functions as func
import logging
import json
import re
import random

app = func.FunctionApp()

def contains_inappropriate_language(prompt):
    inappropriate_words = [
        'mierda', 'idiota', 'est√∫pido', 'imb√©cil', 
        'pendejo', 'hijo de puta', 'gilipollas'
    ]
    
    prompt_lower = prompt.lower()
    
    for word in inappropriate_words:
        if word in prompt_lower:
            return True
    
    return False

def detect_prompt_intention(prompt):
    """
    An√°lisis m√°s detallado de la intenci√≥n del prompt
    """
    intention_patterns = {
        'learning': [
            r'\b(aprender|explicar|entender|comprender)\b',
            r'\b(c√≥mo funciona|qu√© es|significado)\b'
        ],
        'problem_solving': [
            r'\b(resolver|ayuda|soluci√≥n|problema|diagnosticar)\b',
            r'\b(c√≥mo puedo|qu√© debo hacer)\b'
        ],
        'creative': [
            r'\b(imaginar|crear|dise√±ar|inventar|proponer)\b',
            r'\b(nueva idea|innovaci√≥n|concepto)\b'
        ],
        'analytical': [
            r'\b(analizar|investigar|estudiar|examinar)\b',
            r'\b(impacto|consecuencias|desarrollo)\b'
        ],
        'technical': [
            r'\b(algoritmo|inteligencia artificial|machine learning|tecnolog√≠a)\b',
            r'\b(programaci√≥n|c√≥digo|sistema|computaci√≥n)\b'
        ]
    }
    
    detected_intentions = []
    
    for intention, patterns in intention_patterns.items():
        for pattern in patterns:
            if re.search(pattern, prompt.lower()):
                detected_intentions.append(intention)
                break
    
    return detected_intentions if detected_intentions else ['general']

def detect_context_and_improve(prompt):
    """
    Detecta el contexto del prompt
    """
    context_patterns = {
        'learning': [
            r'\b(explicame|qu√© es|c√≥mo funciona)\b',
            r'\b(entender|comprender)\b'
        ],
        'problem_solving': [
            r'\b(resolver|problema|ayuda|soluci√≥n)\b',
            r'\b(c√≥mo puedo|qu√© debo hacer)\b'
        ],
        'creative': [
            r'\b(imagina|crea|dise√±a|inventa|prop√≥n)\b',
            r'\b(nueva idea|innovaci√≥n|concepto)\b'
        ],
        'technical': [
            r'\b(tecnolog√≠a|algoritmo|sistema|m√©todo)\b',
            r'\b(desarrollo|implementaci√≥n)\b'
        ]
    }
    
    for context, patterns in context_patterns.items():
        for pattern in patterns:
            if re.search(pattern, prompt.lower()):
                return context
    
    return 'general'

def analyze_prompt_complexity(prompt):
    """
    Analiza la complejidad y profundidad del prompt
    """
    # M√©tricas de complejidad
    word_count = len(prompt.split())
    unique_words = len(set(prompt.lower().split()))
    
    # Detecci√≥n de palabras t√©cnicas o especializadas
    technical_words = [
        'algoritmo', 'inteligencia', 'machine learning', 
        'neural', 'computacional', 'cu√°ntico', 'blockchain'
    ]
    
    technical_word_count = sum(1 for word in technical_words if word in prompt.lower())
    
    # Clasificaci√≥n de complejidad
    complexity_level = 'basic'
    if word_count > 10 and unique_words > 8:
        complexity_level = 'intermediate'
    if technical_word_count > 0 or word_count > 15:
        complexity_level = 'advanced'
    
    # An√°lisis de profundidad
    depth_indicators = {
        'basic': ['simple', 'general', 'introducci√≥n'],
        'intermediate': ['detallado', 'explicaci√≥n', 'an√°lisis'],
        'advanced': ['profundo', 'complejo', 'especializado']
    }
    
    depth = random.choice(depth_indicators[complexity_level])
    
    return {
        'word_count': word_count,
        'unique_words': unique_words,
        'technical_words': technical_word_count,
        'complexity_level': complexity_level,
        'depth': depth
    }

def generate_improvement_suggestions(intentions, context, complexity=None):
    """
    Genera sugerencias de mejora basadas en la intenci√≥n, contexto y complejidad
    """
    suggestion_templates = {
        'learning': [
            "Profundice en los conceptos fundamentales.",
            "Considere incluir ejemplos pr√°cticos para una mejor comprensi√≥n."
        ],
        'problem_solving': [
            "Proporcione m√°s detalles sobre el contexto del problema.",
            "Incluya informaci√≥n sobre los recursos o herramientas disponibles."
        ],
        'creative': [
            "Explore l√≠mites y restricciones para guiar la creatividad.",
            "Considere el impacto potencial de su idea innovadora."
        ],
        'technical': [
            "Especifique el nivel de conocimiento t√©cnico requerido.",
            "Considere el ecosistema tecnol√≥gico relevante."
        ],
        'general': [
            "Sea m√°s espec√≠fico en su solicitud.",
            "Proporcione contexto adicional para una mejor comprensi√≥n."
        ]
    }
    
    # Combinar sugerencias basadas en intenciones y contexto
    suggestions = []
    for intention in intentions:
        if intention in suggestion_templates:
            suggestions.extend(
                random.sample(suggestion_templates[intention], 
                              min(1, len(suggestion_templates[intention])))
            )
    
    # Sugerencias basadas en complejidad
    if complexity:
        if complexity.get('complexity_level') == 'basic':
            suggestions.append("Considere expandir su prompt para obtener informaci√≥n m√°s detallada.")
        elif complexity.get('complexity_level') == 'advanced':
            suggestions.append("Su prompt parece ser muy t√©cnico. Aseg√∫rese de que la audiencia comprender√° la terminolog√≠a.")
    
    return suggestions

@app.route(route="preprocess_prompt", methods=["POST"])
def preprocess_prompt_endpoint(req: func.HttpRequest) -> func.HttpResponse:
    try:
        req_body = req.get_json()
        prompt = req_body.get('prompt', '')
        
        if not prompt:
            return func.HttpResponse(
                json.dumps({"error": "Prompt vac√≠o"}),
                status_code=400,
                mimetype="application/json"
            )
        
        # Inicializar resultado
        result = {
            'original_prompt': prompt,
            'processed_prompt': prompt,
            'issues': [],
            'suggestions': [],
            'risk_level': 'low',
            'intention': None,
            'context': None,
            'complexity': None
        }
        
        # Validaci√≥n de longitud
        if len(prompt) < 5:
            result['issues'].append('short_prompt')
            result['suggestions'].append(
                'El prompt es demasiado corto. Por favor, proporcione m√°s contexto.'
            )
        
        # Validaci√≥n de lenguaje inapropiado
        if contains_inappropriate_language(prompt):
            result['issues'].append('inappropriate_language')
            result['suggestions'].append(
                'Se detectaron palabras inapropiadas. Por favor, use un lenguaje respetuoso.'
            )
            result['risk_level'] = 'high'
        
        # Detecci√≥n de intenci√≥n
        intentions = detect_prompt_intention(prompt)
        result['intention'] = intentions
        
        # Detecci√≥n de contexto
        context = detect_context_and_improve(prompt)
        result['context'] = context
        
        # An√°lisis de complejidad
        complexity_analysis = analyze_prompt_complexity(prompt)
        result['complexity'] = complexity_analysis
        
        # Generar sugerencias de mejora
        improvement_suggestions = generate_improvement_suggestions(
            intentions, 
            context,
            result['complexity']
        )
        result['suggestions'].extend(improvement_suggestions)
        
        return func.HttpResponse(
            json.dumps(result),
            status_code=200,
            mimetype="application/json"
        )
    
    except Exception as e:
        logging.error(f"Error en procesamiento: {str(e)}")
        return func.HttpResponse(
            json.dumps({"error": str(e)}),
            status_code=500,
            mimetype="application/json"
        )
```
### **Acciones:**

- Verifica si el prompt contiene lenguaje inapropiado.
- Detecta la intenci√≥n del prompt.
- Identifica el contexto del prompt.
- Analiza la complejidad del prompt.
- Genera sugerencias de mejora.
- Asigna un nivel de riesgo basado en el contenido del prompt.


2. Archivo `requirements.txt`:
```
azure-functions==1.17.0
azure-ai-contentsafety==1.0.0
openai==1.3.0
spacy==3.5.2
textblob==0.17.1
profanity-check==1.0.7
https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.5.0/es_core_news_sm-3.5.0-py3-none-any.whl
python-dotenv==1.0.0
setuptools
wheel
```

3. Archivo `host.json`:
```
{
    "version": "2.0",
    "logging": {
        "applicationInsights": {
            "samplingSettings": {
                "isEnabled": true,
                "excludedTypes": "Request"
            }
        }
    },
    "extensionBundle": {
        "id": "Microsoft.Azure.Functions.ExtensionBundle",
        "version": "[3.*, 4.0.0)"
    }
}
```
4. Archivo `local.settings.json`:
```
{
    "IsEncrypted": false,
    "Values": {
        "AzureWebJobsStorage": "",
        "FUNCTIONS_WORKER_RUNTIME": "python",
        "OPENAI_API_KEY": "tu_clave_de_openai",
        "AZURE_CONTENT_SAFETY_ENDPOINT": "tu_endpoint_de_content_safety",
        "AZURE_CONTENT_SAFETY_KEY": "tu_clave_de_content_safety",
        "SPACY_MODEL": "es_core_news_sm"  // A√±adido para referencia del modelo
    }
}
```
5. Agregarle al archivo `.gitignore`: 
```

*.pyc

```
### 4Ô∏è‚É£ **Crear Azure Function App**  
üí° **Funci√≥n principal donde correr√° nuestra validaci√≥n.**  

1. Iniciar sesi√≥n en Azure: 
```
az login
```
2. Crear recursos de Azure: 
```
 # Crear grupo de recursos
# A√±adir regi√≥n como variable, elegimos 'eastus2' ya que soporta el plan flex-consumption(y dentro de √©l tenemos python)
REGION="eastus2"
az group create --name MyPythonFunctionsGroup --location $REGION
```
```

# Crear cuenta de storage (requerida para Functions)
STORAGE_ACCOUNT="almacenhackathonmarzo"
az storage account create \
    --name $STORAGE_ACCOUNT \
    --location $REGION \
    --resource-group MyPythonFunctionsGroup \
    --sku Standard_LRS

```
```
# A veces hay demasiada latencia y no nos permite continuar con los scripts ya que no llegan a crearse las instancias en el portal, para que ello no suceda, he aqui un scrip que esperar√° dinamicamente que la cuenta de almacenamiento est√© disponible: 

echo "Verificando la cuenta de almacenamiento..."
while ! az storage account show --name $STORAGE_ACCOUNT --resource-group MyPythonFunctionsGroup &>/dev/null; do
    echo "Esperando a que la cuenta de almacenamiento est√© disponible..."
    sleep 10
done
echo "Cuenta de almacenamiento detectada, continuando..."
```
```
# Crear el plan de consumo Flex Consumption que, como ya dijimos mas arriba es el que soporta Python
az functionapp plan create \
    --resource-group MyPythonFunctionsGroup \
    --name my-flex-consumption-plan \
    --location $REGION \
    --sku EP1 \
    --is-linux
```
```

# Crear Function App
az functionapp create \
    --resource-group MyPythonFunctionsGroup \
    --plan my-flex-consumption-plan \
    --os-type Linux \
    --runtime python \
    --runtime-version 3.9 \
    --functions-version 4 \
    --name mypythonfunctionapp \
    --storage-account $STORAGE_ACCOUNT
```
3. Verificacion:
```
az functionapp list --resource-group MyPythonFunctionsGroup --query "[].{Name:name, Runtime:siteConfig.linuxFxVersion, OS:reserved}"
```
    . Este comando deberia devolver: 
```
[
  {
    "Name": "mypythonfunctionapp",
    "OS": true,
    "Runtime": "Python|3.9"
  }
]
```

### 5Ô∏è‚É£ **Continuar trabajando en local:**
1. Crear entorno virtual y descargar spacy:
```
# Antes de activar, asegurarse de tener la √∫ltima versi√≥n de pip
python -m pip install --upgrade pip
```
```
# Crear entorno en Python 3.9, en este caso lo instalar√© usando "pyenv"
pyenv install 3.9.21
```
```
python -m venv venv
```
```
# Activar en windows:
.\venv\Scripts\activate

# Activar en Linux/Mac:
source venv/bin/activate
```
```
# Instalar dependencias
pip install -r requirements.txt

# Instalar modelo de spaCy
python -m spacy download es_core_news_sm
```
2. Probar localmente:
```
func start
```
### 6Ô∏è‚É£ **Desplegar en Azure:**
```
# Publicar Function App
func azure functionapp publish mypythonfunctionapp
# Tambien se podria a√±adir flag para mostrar mas detalles:
# func azure functionapp publish mypythonfunctionapp --verbose (opcional)
```
---
